import os
import streamlit as st
import boto3
from botocore.exceptions import NoCredentialsError, ClientError
from dotenv import load_dotenv
from io import BytesIO
import pandas as pd
import plotly.express as px
import base64
import plotly.figure_factory as ff
import json
import streamlit.components.v1 as components



# Carregar variÃ¡veis de ambiente
load_dotenv()

# Configurar cliente do boto3
s3 = boto3.client(
    "s3",
    aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
)

BUCKET_NAME = os.getenv("AWS_STORAGE_BUCKET_NAME")


# FunÃ§Ã£o para listar os arquivos no bucket S3
st.cache_data(show_spinner=False)


def listar_arquivos_s3():
    return s3.list_objects_v2(Bucket=BUCKET_NAME)["Contents"]


# FunÃ§Ã£o para baixar e carregar arquivo Parquet do S3
st.cache_data(hash_funcs={boto3.client: id}, show_spinner=False)


def carregar_parquet_s3(file_key):
    s3_object = s3.get_object(Bucket=BUCKET_NAME, Key=file_key)
    data = s3_object["Body"].read()  # Isso Ã© um conjunto de bytes, nÃ£o uma string
    return pd.read_parquet(BytesIO(data))  # Polars lÃª diretamente do objeto de bytesz


def load_json_s3(s3, bucket_name, file_key):
    """
    Esta funÃ§Ã£o baixa e lÃª um arquivo JSON do S3,
    retornando um DataFrame do Pandas.
    """
    obj = s3.get_object(Bucket=bucket_name, Key=file_key)
    data = json.loads(obj["Body"].read())
    df = pd.json_normalize(data)  # Transforma o JSON em um dataframe
    return df


@st.cache_data
def convert_df(df):
    return df.to_csv(index=False).encode("utf-8")


def main():
    # Para imagens na internet, vocÃª pode usar o link direto para a imagem.

    st.title(f"AnÃ¡lise Airbnb - SÃ³ os TOP :moneybag: :moneybag: :moneybag:")

    st.subheader("NÃ£o sei pq vocÃªs tiraram o de 600k, aqui Ã© tudo 10k +")

    st.subheader("Como o stakeholder vai pedir, toma aqui o EXCEL logo")

    st.subheader("  ")
    st.subheader("  ")

    try:
        # Obtendo lista de arquivos no bucket
        objects = s3.list_objects_v2(Bucket=BUCKET_NAME)["Contents"]

        # Filtrar arquivos JSON
        json_objects = [obj for obj in objects if obj["Key"].endswith(".json")]

        # DataFrame vazio para armazenar dados dos arquivos JSON
        json_df = pd.DataFrame()

        # Iterar sobre cada arquivo JSON, baixar, converter para DataFrame e concatenar
        for obj in json_objects:
            df = load_json_s3(s3, BUCKET_NAME, obj["Key"])
            json_df = pd.concat([json_df, df], ignore_index=True)

    except Exception as e:
        st.error(f"Erro ao carregar ou processar arquivos JSON do S3: {e}")
        return

    try:
        # Listando os arquivos no bucket S3
        objects = listar_arquivos_s3()

        # Se nÃ£o hÃ¡ objetos, uma exceÃ§Ã£o KeyError seria lanÃ§ada
        if not objects:
            st.write("Nenhum objeto no bucket.")
            return

    except NoCredentialsError:
        st.error("Credenciais da AWS nÃ£o encontradas.")
        return
    except ClientError as e:
        st.error(f"Erro ao acessar o bucket S3: {e}")
        return

    # Filtrar arquivos Parquet
    parquet_files = [file for file in objects if file["Key"].endswith(".parquet")]

    if not parquet_files:
        st.write("Nenhum arquivo Parquet encontrado.")
        return

    # Supondo que estamos trabalhando apenas com o arquivo Parquet mais recente
    latest_parquet = sorted(
        parquet_files, key=lambda x: x["LastModified"], reverse=True
    )[0]
    file_key = latest_parquet["Key"]

    try:
        # Carregando e lendo o arquivo Parquet
        df_p = carregar_parquet_s3(file_key)

        # ---- Sidebar com Filtros ----

        df = pd.concat([df_p, json_df], ignore_index=True)

        st.sidebar.title("Filtros")

        # Filtro para a cidade
        unique_cities = sorted(df["city"].unique())
        selected_cities = st.sidebar.multiselect("Cidade", unique_cities, unique_cities)

        # Filtro para a faixa de preÃ§o
        min_price, max_price = df["price"].min(), df["price"].max()
        price_range = st.sidebar.slider(
            "Faixa de PreÃ§o",
            int(min_price),
            int(max_price),
            (int(min_price), int(max_price)),
        )

        # Aplicando os filtros ao dataframe
        filtered_df = df[
            (df["city"].isin(selected_cities))
            & (df["price"] >= price_range[0])
            & (df["price"] <= price_range[1])
        ]

        # ---- AnÃ¡lises e VisualizaÃ§Ãµes ----

        # Criar colunas para as mÃ©tricas
        col4, col5, col6 = st.columns(3)

        csv = convert_df(df)

        with col5:
            st.download_button(
                "BotÃ£o de Download do Excel",
                csv,
                "file.csv",
                "text/csv",
                key="download-csv",
            )

        st.subheader("  ")
        st.subheader("  ")
        # ---- MÃ©tricas ----

        # Calcular mÃ©tricas
        avg_price = filtered_df["price"].mean()
        median_price = filtered_df["price"].median()
        max_price = filtered_df["price"].max()

        # Criar colunas para as mÃ©tricas
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(label="PreÃ§o MÃ©dio", value=f"${avg_price:,.2f}")
        with col2:
            st.metric(label="PreÃ§o Mediano", value=f"${median_price:,.2f}")
        with col3:
            st.metric(label="PreÃ§o MÃ¡ximo", value=f"${max_price:,.2f}")

        # ---- AnÃ¡lise de preÃ§o ----

        # PreÃ§o mediano por cidade como um grÃ¡fico de barras
        median_price_city = (
            filtered_df.groupby("city")["price"].median().sort_values(ascending=False)
        )

        # Criando um DataFrame a partir dos dados agregados para facilitar a plotagem
        median_price_df = pd.DataFrame(median_price_city).reset_index()

        # Criando o grÃ¡fico de barras com Plotly
        fig = px.bar(
            median_price_df,
            x="city",
            y="price",
            text="price",  # Isso adicionarÃ¡ o valor da barra em cima de cada barra
            labels={"price": "PreÃ§o Mediano", "city": "Cidade"},  # renomeia as labels
            color_discrete_sequence=["#636EFA"]
            * len(median_price_df),  # define uma Ãºnica cor para todas as barras
            title="Um grÃ¡fico de barra para mostrar um preÃ§o mÃ©dio por cidade",
        )
        fig.update_traces(
            texttemplate="%{text:.2s}", textposition="outside"
        )  # Formatar o texto
        fig.update_layout(
            yaxis=dict(title="PreÃ§o Mediano"),
            xaxis=dict(title="Cidade"),
            showlegend=False,  # Esconde a legenda
        )

        st.plotly_chart(fig)

        st.subheader("  ")
        st.subheader("  ")

        fig = px.histogram(
            filtered_df,
            x="price",
            nbins=50,
            title="Um histograma para mostrar frequÃªncia",
        )
        fig.update_xaxes(title="PreÃ§o")
        fig.update_yaxes(title="Quantidade de casas para alugar")
        fig.update_layout(
            showlegend=False
        )  # VocÃª pode remover a legenda se nÃ£o estiver usando cores diferentes para as barras

        st.plotly_chart(fig)

        # ---- AnÃ¡lise de Reviews ----

        # Histograma das AvaliaÃ§Ãµes Gerais
        fig = px.histogram(
            filtered_df,
            x="review_scores_rating",
            nbins=20,
            title="Outro histograma para fingir que sei estatÃ­stica",
        )
        st.plotly_chart(fig)

        st.subheader("  ")
        st.subheader("  ")

        # Aqui, estamos apenas selecionando algumas colunas para fins de demonstraÃ§Ã£o. VocÃª pode escolher diferentes colunas baseadas em seu dataset.
        heatmap_data = filtered_df[
            ["price", "review_scores_rating", "bedrooms", "accommodates"]
        ].dropna()

        # Calculando correlaÃ§Ãµes
        correlations = heatmap_data.corr()

        # Criando o mapa de calor
        st.subheader("Esse aqui Ã© impressiona atÃ© o TÃ©o")
        fig = ff.create_annotated_heatmap(
            z=correlations.values,
            x=list(correlations.columns),
            y=list(correlations.index),
            annotation_text=correlations.round(2).values,
            showscale=True,
            colorscale="Viridis",
        )

        st.plotly_chart(fig)

        st.subheader("  ")
        st.subheader("  ")

        st.subheader("Um grÃ¡fico 3D muito bonito - que gira!")
        fig = px.scatter_3d(
            filtered_df,
            x="latitude",
            y="longitude",
            z="price",
            color="price",  # isso vai colorir os pontos com base no preÃ§o
            title="PreÃ§o das listagens em relaÃ§Ã£o Ã  localizaÃ§Ã£o",
            labels={
                "latitude": "Latitude",
                "longitude": "Longitude",
                "price": "PreÃ§o",
            },  # renomeia os labels dos eixos
            opacity=0.5,  # vocÃª pode ajustar a opacidade dos pontos
        )
        fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))

        st.plotly_chart(fig)

        st.subheader("  ")
        st.subheader("  ")
        st.subheader("  ")
        st.subheader("  ")

        # Mapa com as listagens
        st.subheader("Um grÃ¡fico de mapa, pq sempre fica bonito nÃ©?")
        st.map(filtered_df)

        st.subheader("  ")
        st.subheader("  ")

        # Adicionando um toque de humor e leveza ao texto
        st.markdown(
            """
            ### ðŸ˜… Ok... Dataviz nÃ£o Ã© minha praia...
            Mas cara, dÃª uma olhada na magia do streaming acontecendo! âœ¨
            """
        )

        st.markdown(
            """
            ðŸ”¥ Sim, todos os dados que vocÃª vÃª aqui sÃ£o servidos em *real-time*! ðŸ”¥
            """
        )

        st.markdown(
            """
            ðŸš€ **Desafio Aceito?** Vamos testar?
            """
        )

        # Quantidade de listagens
        num_listings = len(filtered_df)
        st.markdown(
            f"""ðŸŽ‰ Aqui estÃ¡ o nÃºmero total de reservas atuais: **{num_listings}**. """)
        
        st.markdown("Fique de olho nisso... algo especial estÃ¡ prestes a acontecer! ðŸŒŸ")

        st.markdown(
            """
            ðŸŒˆ Temos uma API que faz POST usando a FastAPI, tem um vÃ­deo ensinando como usar
            """
        )

            # HTML para renderizar o vÃ­deo
        video_embed_code = """
        <div style="position: relative; padding-bottom: 62.5%; height: 0;">
            <iframe src="https://www.loom.com/embed/d93390c5513547e59e3f8f00e33712a3?sid=89a6857f-eb7e-449a-a6fb-8cd532341e7f" 
                    frameborder="0" 
                    webkitallowfullscreen 
                    mozallowfullscreen 
                    allowfullscreen 
                    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
        </div>
        """

        # Renderizando o vÃ­deo no Streamlit
        components.html(video_embed_code, height=450)  # VocÃª pode ajustar a altura conforme necessÃ¡rio

        st.link_button(url="https://fivedataglowup.onrender.com/", label="Link para a API")

        st.markdown(
            """
            ðŸ‘€ E ai testou? Viu que o nÃºmero realmente foi alterado?
            Abaixo, vocÃª pode olhar o conteÃºdo dos Ãºltimos 5 arquivos que foram lanÃ§ados no nosso banco - e checar o seu!
            """
        )
        # Lista para armazenar os Ãºltimos 5 JSONs ordenados por Ãºltima modificaÃ§Ã£o
        latest_jsons = sorted(
            [
                obj for obj in objects if obj["Key"].endswith(".json")
            ],  # Filtrando para incluir apenas JSONs
            key=lambda x: x["LastModified"],
            reverse=True,
        )[:5]

        # Lista para armazenar os conteÃºdos dos Ãºltimos 5 JSONs
        latest_json_contents = []

        for file in latest_jsons:
            file_key = file[
                "Key"
            ]  # Aqui estava o erro. VocÃª precisa do nome do arquivo, nÃ£o de um booleano.

            try:
                # Baixando o arquivo do S3
                s3_object = s3.get_object(Bucket=BUCKET_NAME, Key=file_key)
                data = s3_object["Body"].read()
                json_content = json.loads(data)

                # Adicionar o JSON Ã  lista de conteÃºdos
                latest_json_contents.append((file_key, json_content))

            except ClientError as e:
                st.error(f"Erro ao recuperar o arquivo {file_key}: {e}")
                continue
            except json.JSONDecodeError:
                st.error(
                    f"NÃ£o foi possÃ­vel decodificar o arquivo {file_key} como JSON."
                )
                continue

        # Exibir os Ãºltimos 5 JSONs
        st.subheader("Ãšltimos 5 JSONs (ordenados por Ãºltima modificaÃ§Ã£o no S3)")
        for i, (file_key, json_content) in enumerate(latest_json_contents, 1):
            with st.expander(
                f"JSON {i} - Ãšltima modificaÃ§Ã£o: {latest_jsons[i-1]['LastModified']}"
            ):
                st.text(f"Nome do arquivo: {file_key}")
                st.json(
                    json_content
                )  # Esta funÃ§Ã£o exibe dados no formato JSON de maneira formatada.
        
        st.markdown(
            """
            ## Legal nÃ©? Mas vocÃª reparou em uma coisa?...
            Apesar do FastAPI ter toda uma validaÃ§Ã£o de schema e de datatype
            """)

        st.subheader("  ")

        st.markdown(
            """
            ## NÃ£o validamos REGRAS DE NEGÃ“CIO!
            """)

        st.subheader("  ")

        st.markdown(
            """
            Como assim? Olha lÃ¡ em cima
            """)
        
        st.subheader("  ")

        st.markdown(
            """
            Tem uma cidade chamada STRING, valores MENORES que 10k e um ponto no MEIO DO MAR!
            """)
        
        st.subheader("  ")

        st.markdown(
            """
            Ou seja.... se isso aqui fosse uma aplicaÃ§Ã£o teria muitos problema de integridade de dados.
            """)
        
        st.subheader("  ")

        st.markdown(
            """
            E Ã© ai que entra uma sÃ©rie de estratÃ©gias de valiÃ§Ã£o de dados!
            """)
        
        st.subheader("  ")

        st.markdown(
            """
            Se vocÃª quer aprender mais sobre e for de vitÃ³ria, tenho um convite para vocÃª!
            """)
        
        st.subheader("  ")

        st.markdown(
            """
            ## No dia 28 de outubro, vou fazer um workshop de dataquality para Dashboards!
            """)
        
        st.subheader("  ")
        st.subheader("  ")

        st.image("https://i.postimg.cc/rwVtZm22/eu.jpg", use_column_width=True, width=50)

        st.subheader("  ")

        st.markdown(
            """
            Legal nÃ©? Vai lÃ¡ no evento, ta cheio de cara fera e eu kkk
            """)
        
        st.subheader("  ")

        st.link_button(url="https://www.sympla.com.br/evento/data-saturday-1065-vitoria-2023/2172362?referrer=www.google.com", label="Link para o evento")
        
        st.markdown(
            """
            ## Se vocÃª nÃ£o for de vitÃ³ria, curte e comenta aqui no post para me ajudar a divulgar o evento! :D
            """)


    except ClientError as e:
        st.error(f"Erro ao recuperar o arquivo {file_key}: {e}")
    except (
        Exception
    ) as e:  # Captura outros possÃ­veis erros durante a leitura do Parquet
        st.error(f"Erro ao ler o arquivo Parquet: {e}")

    
        # Mapa com as listagens
        st.subheader("Um meme")
        image_url = "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQOad1ujU6HSAeVv-_2LcO2wUklgmXen5LATg&usqp=CAU"
        st.image(image_url, use_column_width=True)


if __name__ == "__main__":
    main()
